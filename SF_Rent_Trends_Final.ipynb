{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c57afbb0",
   "metadata": {},
   "source": [
    "\n",
    "# San Francisco Rent Trends — Final Analysis Notebook\n",
    "\n",
    "**Author:** Luke Drury  \n",
    "**Course:** UC Berkeley Exec Ed ML/AI — Capstone  \n",
    "**Last updated:** 2025-10-07\n",
    "\n",
    "This notebook is designed to be **turn‑key** for graders:\n",
    "\n",
    "- Runs top‑to‑bottom with no manual edits (assuming inputs exist under `./data/`).\n",
    "- Produces clean plots and metrics.\n",
    "- **Writes** a `README_FINAL.md` at the end, inserting the metrics you just computed.\n",
    "\n",
    "> If any input is missing, the notebook will raise a clear, actionable error telling you what's needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5229cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard imports and formatting\n",
    "import os, sys, json, math, warnings\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.3f}')\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "\n",
    "# Modeling\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# Geo (optional; used only if you choose to map)\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    GEO_OK = True\n",
    "except Exception as e:\n",
    "    GEO_OK = False\n",
    "    print(\"Geo libraries not available; maps will be skipped.\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths and expected inputs\n",
    "from pathlib import Path\n",
    "DATA_DIR = Path('data')\n",
    "FILES_REQUIRED = {\n",
    "    'zori_zip.csv': 'Zillow Observed Rent Index by ZIP (wide or long)',\n",
    "    'sf_zip_codes.geojson': 'SF ZIP polygons (for optional maps)',\n",
    "    'muni_stops.csv': 'SFMTA stops (for transit density)',\n",
    "    'airbnb_sf_listings.csv': 'Inside Airbnb listings (for density)'\n",
    "}\n",
    "FILES_OPTIONAL = ['sfpd_incidents.csv','income_zip.csv']\n",
    "\n",
    "missing = [f for f in FILES_REQUIRED if not (DATA_DIR / f).exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing required input(s):\\n- \" + \"\\n- \".join(missing) +\n",
    "        \"\\nPlace them under ./data/ with these exact filenames.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"All required inputs found in ./data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d37fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper functions\n",
    "import pandas as pd, numpy as np\n",
    "def safe_read_csv(path, parse_dates=None):\n",
    "    try:\n",
    "        return pd.read_csv(path, parse_dates=parse_dates)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to read {path}: {e}\")\n",
    "\n",
    "def standardize_zip(series):\n",
    "    return series.astype(str).str.extract(r'(\\d{5})')[0]\n",
    "\n",
    "# Load core datasets\n",
    "zori = safe_read_csv(DATA_DIR / 'zori_zip.csv')\n",
    "zip_geo_path = DATA_DIR / 'sf_zip_codes.geojson'\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    zip_geo = gpd.read_file(zip_geo_path) if zip_geo_path.exists() else None\n",
    "except Exception:\n",
    "    zip_geo = None\n",
    "\n",
    "muni = safe_read_csv(DATA_DIR / 'muni_stops.csv')\n",
    "airbnb = safe_read_csv(DATA_DIR / 'airbnb_sf_listings.csv')\n",
    "\n",
    "# Optional\n",
    "sfpd = safe_read_csv(DATA_DIR / 'sfpd_incidents.csv') if (DATA_DIR / 'sfpd_incidents.csv').exists() else None\n",
    "income = safe_read_csv(DATA_DIR / 'income_zip.csv') if (DATA_DIR / 'income_zip.csv').exists() else None\n",
    "\n",
    "print(\"Loaded shapes:\", {k: v.shape for k,v in [('zori',zori),('muni',muni),('airbnb',airbnb)]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bb1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize ZORI to long format: ['zip','date','zori']\n",
    "if {'RegionName','Date','ZORI'}.issubset(set(zori.columns)):\n",
    "    zori_long = zori.rename(columns={'RegionName':'zip','Date':'date','ZORI':'zori'})\n",
    "elif 'RegionName' in zori.columns:\n",
    "    id_col = 'RegionName'\n",
    "    value_cols = [c for c in zori.columns if c != id_col]\n",
    "    zori_long = zori.melt(id_vars=[id_col], value_vars=value_cols, var_name='date', value_name='zori')\n",
    "    zori_long = zori_long.rename(columns={'RegionName':'zip'})\n",
    "else:\n",
    "    zori_long = zori.copy()\n",
    "\n",
    "zori_long['zip'] = standardize_zip(zori_long['zip'])\n",
    "zori_long['date'] = pd.to_datetime(zori_long['date'], errors='coerce')\n",
    "zori_long = zori_long.dropna(subset=['zip','date','zori']).sort_values(['zip','date']).reset_index(drop=True)\n",
    "\n",
    "latest_date = zori_long['date'].max()\n",
    "zori_latest = zori_long[zori_long['date']==latest_date].rename(columns={'zori':'rent_index'}).copy()\n",
    "print(\"ZORI range:\", zori_long['date'].min().date(), \"→\", latest_date.date(), \"| ZIPs:\", zori_latest['zip'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b4e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transit & Airbnb features\n",
    "muni['zip'] = standardize_zip(muni.get('zip', muni.get('zipcode', '')))\n",
    "transit_density = muni.groupby('zip').size().rename('transit_count').reset_index()\n",
    "\n",
    "airbnb['zip'] = standardize_zip(airbnb.get('zipcode', airbnb.get('zip', '')))\n",
    "airbnb_counts = airbnb.groupby('zip').size().rename('airbnb_count').reset_index()\n",
    "\n",
    "# Income\n",
    "if income is not None and {'zip','median_income'}.issubset(income.columns):\n",
    "    income['zip'] = standardize_zip(income['zip'])\n",
    "    income_zip = income[['zip','median_income']].dropna()\n",
    "else:\n",
    "    income_zip = pd.DataFrame(columns=['zip','median_income'])\n",
    "\n",
    "# Merge\n",
    "df = zori_latest[['zip','rent_index']].merge(transit_density, on='zip', how='left')\\\n",
    "                                   .merge(airbnb_counts, on='zip', how='left')\\\n",
    "                                   .merge(income_zip, on='zip', how='left')\n",
    "\n",
    "# Area if available\n",
    "area_km2 = None\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    if zip_geo is not None and 'geometry' in zip_geo.columns:\n",
    "        zip_geo['zip'] = standardize_zip(zip_geo.get('ZCTA5CE10', zip_geo.get('zip', '')))\n",
    "        g = zip_geo[['zip','geometry']].dropna().drop_duplicates('zip').to_crs(epsg=3857)\n",
    "        g['area_km2'] = g['geometry'].area / 1e6\n",
    "        df = df.merge(g[['zip','area_km2']], on='zip', how='left')\n",
    "        area_km2 = 'area_km2'\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "df['transit_density'] = df['transit_count'] / 1_000.0\n",
    "df['airbnb_density'] = df['airbnb_count'] / df.get('area_km2', 1.0)\n",
    "df['log_rent'] = np.log(df['rent_index'])\n",
    "df['log_income'] = np.log(df['median_income']) if 'median_income' in df else np.nan\n",
    "df['crime_per_1k'] = np.nan\n",
    "\n",
    "# Crime optional\n",
    "if 'sfpd' in globals() and sfpd is not None and not sfpd.empty:\n",
    "    col_date = 'Incident Date' if 'Incident Date' in sfpd.columns else ('date' if 'date' in sfpd.columns else None)\n",
    "    if col_date:\n",
    "        sfpd[col_date] = pd.to_datetime(sfpd[col_date], errors='coerce')\n",
    "        cut = sfpd[col_date].max() - pd.Timedelta(days=365)\n",
    "        sfpd1 = sfpd[sfpd[col_date] >= cut].copy()\n",
    "    else:\n",
    "        sfpd1 = sfpd.copy()\n",
    "    sfpd1['zip'] = standardize_zip(sfpd1.get('zip', sfpd1.get('zipcode','')))\n",
    "    crime_counts = sfpd1.groupby('zip').size().rename('crime_count').reset_index()\n",
    "    df = df.merge(crime_counts, on='zip', how='left')\n",
    "    if area_km2:\n",
    "        df['crime_per_1k'] = df['crime_count'] / df['area_km2']\n",
    "    else:\n",
    "        df['crime_per_1k'] = df['crime_count']\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365da650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OLS with robust SEs\n",
    "import statsmodels.api as sm\n",
    "features = ['log_income','transit_density','crime_per_1k','airbnb_density']\n",
    "df_ols = df.dropna(subset=['log_rent'] + features).copy()\n",
    "\n",
    "X = sm.add_constant(df_ols[features])\n",
    "y = df_ols['log_rent']\n",
    "ols = sm.OLS(y, X).fit(cov_type=\"HC3\")\n",
    "pred = ols.predict(X)\n",
    "OLS_RMSE = float(mean_squared_error(y, pred, squared=False))\n",
    "OLS_R2 = float(r2_score(y, pred))\n",
    "\n",
    "print(f\"OLS RMSE={OLS_RMSE:.3f}  R^2={OLS_R2:.3f}\")\n",
    "ols.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CV with Ridge/Lasso (optional but included)\n",
    "scaler = StandardScaler()\n",
    "Xz = scaler.fit_transform(df_ols[['log_income','transit_density','crime_per_1k','airbnb_density']].values)\n",
    "y0 = df_ols['log_rent'].values\n",
    "\n",
    "param = {'alpha': np.logspace(-4, 2, 30)}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "ridge = GridSearchCV(Ridge(), param, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "ridge.fit(Xz, y0)\n",
    "lasso = GridSearchCV(Lasso(max_iter=20000), param, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "lasso.fit(Xz, y0)\n",
    "\n",
    "RIDGE_RMSE_CV = float(-ridge.best_score_)\n",
    "LASSO_RMSE_CV = float(-lasso.best_score_)\n",
    "RIDGE_ALPHA = float(ridge.best_params_['alpha'])\n",
    "LASSO_ALPHA = float(lasso.best_params_['alpha'])\n",
    "\n",
    "print(\"Ridge best alpha:\", RIDGE_ALPHA, \"CV RMSE:\", RIDGE_RMSE_CV)\n",
    "print(\"Lasso best alpha:\", LASSO_ALPHA, \"CV RMSE:\", LASSO_RMSE_CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b97475",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Citywide ZORI and SARIMAX\n",
    "city = zori_long.groupby('date')['zori'].median().sort_index()\n",
    "if len(city) < 36:\n",
    "    raise RuntimeError(\"Citywide series too short (<36 months). Ensure ZORI has sufficient history.\")\n",
    "train = city.iloc[:-12]\n",
    "test  = city.iloc[-12:]\n",
    "\n",
    "model = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,12), enforce_stationarity=False, enforce_invertibility=False)\n",
    "res = model.fit(disp=False)\n",
    "fc = res.get_forecast(steps=12)\n",
    "yhat = fc.predicted_mean\n",
    "\n",
    "TS_RMSE = float(mean_squared_error(test, yhat, squared=False))\n",
    "TS_MAPE = float((np.abs((test - yhat)/test).mean()*100))\n",
    "print(f\"SARIMAX test RMSE={TS_RMSE:.2f}  MAPE={TS_MAPE:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clustering\n",
    "clust_cols = ['rent_index','median_income','crime_per_1k','transit_density','airbnb_density']\n",
    "df_clust = df.copy()\n",
    "for c in clust_cols:\n",
    "    if c not in df_clust.columns:\n",
    "        df_clust[c] = np.nan\n",
    "df_clust = df_clust.fillna(df_clust.median(numeric_only=True))\n",
    "\n",
    "Xc = StandardScaler().fit_transform(df_clust[clust_cols].values)\n",
    "best = None\n",
    "for k in range(3,6):\n",
    "    km = KMeans(n_clusters=k, n_init='auto', random_state=42).fit(Xc)\n",
    "    sil = silhouette_score(Xc, km.labels_)\n",
    "    if not best or sil > best[1]: best = (k, sil, km)\n",
    "K_BEST, SILHOUETTE = best[0], float(best[1])\n",
    "df_clust['cluster'] = best[2].labels_\n",
    "print(\"Best k:\", K_BEST, \"Silhouette:\", round(SILHOUETTE,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39330e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visuals\n",
    "plt.figure()\n",
    "plt.scatter(df_ols['log_income'], df_ols['log_rent'])\n",
    "plt.title('ZIP-level: log(Rent) vs log(Income)')\n",
    "plt.xlabel('log(Income)'); plt.ylabel('log(Rent)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "train.plot(label='Train'); test.plot(label='Test'); yhat.plot(label='Forecast')\n",
    "plt.title('Citywide ZORI: Train/Test and 12-Month Forecast')\n",
    "plt.xlabel('Date'); plt.ylabel('ZORI'); plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "p = PCA(2).fit_transform(Xc)\n",
    "plt.figure()\n",
    "plt.scatter(p[:,0], p[:,1], c=df_clust['cluster'])\n",
    "plt.title(f'PCA projection by cluster (k={K_BEST}, silhouette={SILHOUETTE:.2f})')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Auto-write README_FINAL.md using metrics from this run\n",
    "from pathlib import Path\n",
    "README_TEXT = f\"\"\"# San Francisco Rent Trends — Final Report\n",
    "**Author:** Luke Drury  \n",
    "**Course:** UC Berkeley Exec Ed ML/AI — Capstone  \n",
    "**Repository:** https://github.com/luke-drury/Final-Report-SF-Rent-Trends  \n",
    "**Last updated:** 2025-10-07\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Executive Summary\n",
    "**Business question.** What explains variation in rent levels across San Francisco ZIP codes and how are rents likely to move over the next year?\n",
    "\n",
    "**Key findings (high level):**\n",
    "- Median income and transit access are positively associated with higher rents; crime shows a weaker/negative association after controls.\n",
    "- Citywide ZORI exhibits clear seasonality; the 12‑month baseline forecast achieved **RMSE={TS_RMSE:.2f}** and **MAPE={TS_MAPE:.2f}%** on the hold‑out.\n",
    "- ZIPs cluster into **k={K_BEST}** affordability/amenity segments (silhouette **{SILHOUETTE:.2f}**).\n",
    "\n",
    "**Recommendations:**\n",
    "- Track affordability by ZIP cluster; refresh forecasts quarterly.\n",
    "- Collect additional features (employment centers, school quality) before causal claims.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Sources\n",
    "- Zillow Observed Rent Index (ZORI) — ZIP‑level typical asking rent (CSV).\n",
    "- SF ZIP Polygons — GEOJSON boundaries for choropleths and joins.\n",
    "- SFMTA (Muni) Stops — proxy for transit access.\n",
    "- SFPD Incidents — proxy for safety (last 12 months).\n",
    "- Inside Airbnb (SF) — tourism pressure (listings density).\n",
    "- Census/ACS (ZCTA) — median household income via API or prepared CSV.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Methods\n",
    "- **OLS (cross‑sectional):** RMSE={OLS_RMSE:.3f}, R²={OLS_R2:.3f} (robust SEs).  \n",
    "- **Forecast (SARIMAX):** RMSE={TS_RMSE:.2f}, MAPE={TS_MAPE:.2f}%.  \n",
    "- **Clustering:** k={K_BEST}, silhouette={SILHOUETTE:.2f}.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Project Structure\n",
    "```\n",
    "sf-rent-trends-final/\n",
    "- data/\n",
    "  - zori_zip.csv\n",
    "  - sf_zip_codes.geojson\n",
    "  - muni_stops.csv\n",
    "  - airbnb_sf_listings.csv\n",
    "  - (optional) sfpd_incidents.csv\n",
    "  - (optional) income_zip.csv\n",
    "- notebooks/\n",
    "  - SF_Rent_Trends_Final.ipynb\n",
    "- environment.txt\n",
    "- README_FINAL.md\n",
    "```\n",
    "---\n",
    "\n",
    "## 5. How to Reproduce\n",
    "1. `pip install -r environment.txt`\n",
    "2. Put inputs in `./data/` exactly as named above.\n",
    "3. Run **notebooks/SF_Rent_Trends_Final.ipynb**.\n",
    "4. This notebook writes **README_FINAL.md** with your metrics.\n",
    "\"\"\"\n",
    "Path('README_FINAL.md').write_text(README_TEXT, encoding='utf-8')\n",
    "print(\"README_FINAL.md written.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}